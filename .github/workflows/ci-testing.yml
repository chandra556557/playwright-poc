name: CI Testing & Quality Assurance

# Trigger the workflow on push and pull requests
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

# Environment variables
env:
  NODE_VERSION: '18'
  PLAYWRIGHT_BROWSERS_PATH: ${{ github.workspace }}/ms-playwright

# Concurrency settings
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Job 1: Unit and Integration Tests
  unit-integration-tests:
    name: Unit & Integration Tests
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [16, 18, 20]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.npm
            node_modules
            */*/node_modules
          key: ${{ runner.os }}-node-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ matrix.node-version }}-
            ${{ runner.os }}-node-
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:server || npm install
      
      - name: Lint code
        run: |
          npm run lint || echo "Linting not configured"
          npm run lint:server || echo "Server linting not configured"
      
      - name: Type check
        run: |
          npm run type-check || echo "Type checking not configured"
      
      - name: Run unit tests
        run: |
          npm run test:unit || npm run test
        env:
          NODE_ENV: test
          CI: true
      
      - name: Run integration tests
        run: |
          npm run test:integration || echo "Integration tests not configured"
        env:
          NODE_ENV: test
          CI: true
      
      - name: Generate test coverage
        run: |
          npm run test:coverage || npm run test -- --coverage
        env:
          NODE_ENV: test
          CI: true
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
      
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-node-${{ matrix.node-version }}
          path: |
            test-results/
            coverage/
          retention-days: 7
  
  # Job 2: E2E Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: unit-integration-tests
    
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:server || npm install
      
      - name: Install Playwright browsers
        run: |
          npx playwright install --with-deps ${{ matrix.browser }}
      
      - name: Cache Playwright browsers
        uses: actions/cache@v3
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-playwright-${{ matrix.browser }}-${{ hashFiles('**/package-lock.json') }}
      
      - name: Build application
        run: |
          npm run build || npm run build:client
        env:
          NODE_ENV: production
      
      - name: Start application server
        run: |
          npm run start:test &
          sleep 10
        env:
          NODE_ENV: test
          PORT: 3000
      
      - name: Wait for server to be ready
        run: |
          npx wait-on http://localhost:3000 --timeout 60000
      
      - name: Run E2E tests
        run: |
          npm run test:e2e -- --project=${{ matrix.browser }}
        env:
          APP_BASE_URL: http://localhost:3000
          CI: true
      
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-results-${{ matrix.browser }}
          path: |
            test-results/
            playwright-report/
          retention-days: 7
  
  # Job 3: Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: unit-integration-tests
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:server || npm install
      
      - name: Install Playwright browsers
        run: |
          npx playwright install --with-deps chromium
      
      - name: Build application
        run: |
          npm run build || npm run build:client
        env:
          NODE_ENV: production
      
      - name: Start application server
        run: |
          npm run start:test &
          sleep 10
        env:
          NODE_ENV: test
          PORT: 3000
      
      - name: Wait for server to be ready
        run: |
          npx wait-on http://localhost:3000 --timeout 60000
      
      - name: Run performance tests
        run: |
          npm run test:performance || npx playwright test tests/performance/
        env:
          APP_BASE_URL: http://localhost:3000
          CI: true
      
      - name: Upload performance results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-results
          path: |
            test-results/
            performance-report/
          retention-days: 7
  
  # Job 4: Security and Quality Checks
  security-quality:
    name: Security & Quality Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:server || npm install
      
      - name: Run security audit
        run: |
          npm audit --audit-level=moderate
        continue-on-error: true
      
      - name: Check for vulnerabilities
        run: |
          npx audit-ci --moderate
        continue-on-error: true
      
      - name: Run dependency check
        run: |
          npx depcheck || echo "Dependency check completed"
        continue-on-error: true
      
      - name: Check bundle size
        run: |
          npm run build || npm run build:client
          npx bundlesize || echo "Bundle size check completed"
        continue-on-error: true
      
      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        continue-on-error: true
  
  # Job 5: Test Report Generation
  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [unit-integration-tests, e2e-tests, performance-tests]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download all test artifacts
        uses: actions/download-artifact@v3
        with:
          path: ./artifacts
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      
      - name: Install report dependencies
        run: |
          npm install -g allure-commandline
          npm install --save-dev mochawesome-merge mochawesome-report-generator
      
      - name: Generate consolidated test report
        run: |
          # Create consolidated report directory
          mkdir -p consolidated-report
          
          # Copy all test results
          find ./artifacts -name "*.json" -exec cp {} consolidated-report/ \;
          find ./artifacts -name "*.xml" -exec cp {} consolidated-report/ \;
          
          # Generate HTML report if possible
          if [ -f "consolidated-report/results.json" ]; then
            npx marge consolidated-report/results.json --reportDir consolidated-report/html
          fi
          
          # Generate Allure report if allure results exist
          if [ -d "./artifacts/allure-results" ]; then
            allure generate ./artifacts/allure-results -o consolidated-report/allure-report --clean
          fi
        continue-on-error: true
      
      - name: Upload consolidated report
        uses: actions/upload-artifact@v3
        with:
          name: consolidated-test-report
          path: consolidated-report/
          retention-days: 30
      
      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            
            // Read test results and create comment
            let comment = '## ðŸ§ª Test Results\n\n';
            
            // Add coverage information if available
            try {
              const coverageFiles = fs.readdirSync('./artifacts').filter(f => f.includes('coverage'));
              if (coverageFiles.length > 0) {
                comment += '### Coverage Report\n';
                comment += 'Coverage reports have been generated and uploaded as artifacts.\n\n';
              }
            } catch (e) {
              console.log('No coverage files found');
            }
            
            // Add E2E test information
            try {
              const e2eFiles = fs.readdirSync('./artifacts').filter(f => f.includes('e2e-results'));
              if (e2eFiles.length > 0) {
                comment += '### E2E Tests\n';
                comment += `E2E tests completed across ${e2eFiles.length} browser(s).\n\n`;
              }
            } catch (e) {
              console.log('No E2E files found');
            }
            
            // Add performance test information
            try {
              const perfFiles = fs.readdirSync('./artifacts').filter(f => f.includes('performance'));
              if (perfFiles.length > 0) {
                comment += '### Performance Tests\n';
                comment += 'Performance tests completed. Check artifacts for detailed results.\n\n';
              }
            } catch (e) {
              console.log('No performance files found');
            }
            
            comment += '### ðŸ“Š Artifacts\n';
            comment += '- Test results and coverage reports are available in the workflow artifacts\n';
            comment += '- Download artifacts to view detailed HTML reports\n';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
  
  # Job 6: Deployment Preview (for PRs)
  deploy-preview:
    name: Deploy Preview
    runs-on: ubuntu-latest
    needs: [unit-integration-tests, e2e-tests]
    if: github.event_name == 'pull_request' && success()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          npm ci
          npm run install:server || npm install
      
      - name: Build application
        run: |
          npm run build || npm run build:client
        env:
          NODE_ENV: production
      
      - name: Deploy to preview environment
        run: |
          echo "Deploying to preview environment..."
          # Add your deployment commands here
          # Example: Deploy to Vercel, Netlify, or other preview service
        env:
          DEPLOY_TOKEN: ${{ secrets.DEPLOY_TOKEN }}
        continue-on-error: true
      
      - name: Comment PR with preview link
        if: success()
        uses: actions/github-script@v6
        with:
          script: |
            const comment = `## ðŸš€ Preview Deployment\n\n` +
              `Your changes have been deployed to a preview environment.\n` +
              `Preview URL: [View Preview](https://preview-${context.issue.number}.example.com)\n\n` +
              `This preview will be available until the PR is closed.`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });